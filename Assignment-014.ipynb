{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment14.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcueIAWwcKhz",
        "colab_type": "text"
      },
      "source": [
        "# Problem 1 (DS/Algo; 60 min)\n",
        "\n",
        "Extend your `BinaryTree` class. Implement a method `build_from_edges` that builds a binary tree given a list of edges `(parent, child)`.\n",
        "\n",
        "Hint: identify the root and then recursively add on child nodes.\n",
        "\n",
        "```\n",
        ">>> tree = BinaryTree()\n",
        ">>> edges = [('a','c'), ('d','b'), ('a','d'), ('d','f'), ('e','g'), ('f','e'), ('e','a')]\n",
        ">>> tree.build_from_edges(edges)\n",
        "Note: at this point, the tree's internal state should look as follows\n",
        "    e\n",
        "   / \\\n",
        "  a   g\n",
        " /|\n",
        "c d \n",
        " / \\\n",
        "b   f\n",
        "    |\n",
        "    h\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4qlLr6JQMIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uji8A6O66IE9",
        "colab_type": "text"
      },
      "source": [
        "# Problem 2 (ML; 60 min)\n",
        "\n",
        "a) **2-dimensional linear regression** involves finding the line of best fit $y=\\beta_0 + \\beta_1 x$ for a dataset $\\left\\lbrace (x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n) \\right\\rbrace.$\n",
        "\n",
        "In other words, we aim to find the values of $\\beta_0$ and $\\beta_1$ that most closely approximate\n",
        "\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}\n",
        "\\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} &\\approx\n",
        "\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \\\\\n",
        "\\mathbf{X} \\vec{\\beta} &\\approx \\vec{y}\n",
        "\\end{align*}\n",
        "\n",
        "Unfortunately, since $\\mathbf{X}$ is taller than it is wide, it is not invertible. However, $\\mathbf{X}^T \\mathbf{X}$ is invertible, so we have\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbf{X} \\vec{\\beta} &\\approx \\vec{y} \\\\\n",
        "\\mathbf{X}^T \\mathbf{X} \\vec{\\beta} &\\approx \\mathbf{X}^T \\vec{y} \\\\\n",
        "\\vec{\\beta} &\\approx \\left( \\mathbf{X}^T \\mathbf{X} \\right)^{-1} \\mathbf{X}^T \\vec{y}\n",
        "\\end{align*}\n",
        "\n",
        "Write a function `calc_linear_approximation_coefficients(data)` where `data` is a list of points. Use your `Matrix` class within the computation.\n",
        "\n",
        "```\n",
        ">>> on_a_line_data = [(0,1), (1,3), (2,5), (3,7)]\n",
        ">>> calc_linear_approximation_coefficients(not_on_a_line_data)\n",
        "[1, 2]\n",
        ">>> not_on_a_line_data = [(1,4), (2,5), (3,7)]\n",
        ">>> calc_linear_approximation_coefficients(not_on_a_line_data)\n",
        "[2.3333333, 1.5]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBNcTM3ulZ6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq6m-coxbZua",
        "colab_type": "text"
      },
      "source": [
        "b) Extend your recursive function\n",
        "\n",
        "`gradient_descent(f,x0,alpha=0.01,delta=0.001,precision=0.0001)`\n",
        "\n",
        " to a new function\n",
        "\n",
        " `gradient_descent(f,x0,y0,alpha=0.01,delta=0.001,precision=0.0001)`\n",
        "\n",
        " that works on **2-variable functions**.\n",
        "\n",
        "To recursively update your guesses, use the following update:\n",
        "\n",
        "\\begin{align*}\n",
        "x_{n+1} &= x_n - \\alpha f_x(x_n, y_n) \\\\\n",
        "y_{n+1} &= y_n - \\alpha f_y(x_n, y_n)\n",
        "\\end{align*}\n",
        "\n",
        "Note that you will need to write a helper function that computes partial derivatives using an unbiased (centered) difference quotient:\n",
        "\n",
        "\\begin{align*}\n",
        "f_x(x_n, y_n) &\\approx \\dfrac{f(x_n+\\delta, y_n) - f(x_n-\\delta, y_n)}{2\\delta} \\\\\n",
        "f_y(x_n, y_n) &\\approx \\dfrac{f(x_n, y_n+\\delta) - f(x_n, y_n-\\delta)}{2\\delta} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "where $\\delta$ (delta) is chosen as a very small constant. (For our cases, $\\delta = 0.001$ should be sufficient.)\n",
        "\n",
        "The function should recurse until successive guesses are within `precision` amount of each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgeVCy6gbh2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGTnSzc27IL",
        "colab_type": "text"
      },
      "source": [
        "a) Use your gradient descent function to minimize $f(x,y)=1+x^2+y^2$ starting with the initial guess $(1,2).$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnjReEII28Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OcIGvRE28bC",
        "colab_type": "text"
      },
      "source": [
        "b) Use your gradient descent function to minimize $f(x,y) = 3 + (2x-5)^2 + (3y+1)^2.$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vwSFOgA3OU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS0-P5Hle9gp",
        "colab_type": "text"
      },
      "source": [
        "# Problem 3 (SWE; 60 min)\n",
        "\n",
        "Extend your game system.\n",
        "\n",
        "* On each turn, randomly choose to either upgrade technology **or build more ships.**\n",
        "\n",
        "* Implement speed technology. It increases speed in the same way that attack technology increases attack and defense technology increases defense.\n",
        "\n",
        "```\n",
        "Speed Technology Level | Additional CP Cost |\n",
        "---------------------------------------------\n",
        "            0          |         -          |\n",
        "            1          |         90         |\n",
        "            2          |         120        |\n",
        "```\n",
        "\n",
        "* Modify your Scout class so that its default speed is `1`.\n",
        "\n",
        "* **Make it so that a unit's technology level is equal to the technology that existed at the time of building the unit.**\n",
        "\n",
        "  * So, if Scout A is built on turn 1, and then the player purchases speed technology on turn 2, and then builds Scout B on turn 3, then Scout B is faster than Scout A."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDrHm3iifBuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}